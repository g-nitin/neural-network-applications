{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9549795e",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "\n",
    "This notebooks is a gentle introduction to GNNs with PyTorch Lightning.\n",
    "\n",
    "Source: [Tutorial 7: Graph Neural Networks](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753c74d",
   "metadata": {},
   "source": [
    "## Imports and Data Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports and HTTP error handling for downloads\n",
    "import os\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Visualization and training libraries\n",
    "import matplotlib\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.data as geom_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Local utilities: GNN layer and model definitions\n",
    "from utils import GATLayer, GCNLayer, GraphLevelGNN, NodeLevelGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline SVG plots and set style\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "\n",
    "# Reset and apply seaborn styling for consistent visuals\n",
    "sns.reset_orig()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Select device: GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL hosting pretrained checkpoints used by the tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "\n",
    "# Files to download\n",
    "pretrained_files = [\n",
    "    \"NodeLevelMLP.ckpt\",\n",
    "    \"NodeLevelGNN.ckpt\",\n",
    "    \"GraphLevelGraphConv.ckpt\",\n",
    "]\n",
    "\n",
    "# Ensure checkpoint directory exists\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# Download each file only if it's absent to avoid repeated network calls\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971626e1",
   "metadata": {},
   "source": [
    "## Graph Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986c789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a small example: 4 nodes with 2-dim features and an adj matrix (self-loops included)\n",
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate a GCN layer using identity weights so we can inspect aggregation behavior\n",
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = torch.Tensor([0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention probs\n",
      " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
      "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
      "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
      "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
      "\n",
      "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
      "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
      "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
      "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1.2913, 1.9800],\n",
      "         [4.2344, 3.7725],\n",
      "         [4.6798, 4.8362],\n",
      "         [4.5043, 4.7351]]])\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate a GAT layer with two attention heads; set projection/a manually for reproducibility\n",
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = torch.Tensor([0.0, 0.0])\n",
    "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d009204",
   "metadata": {},
   "source": [
    "## Node-Level Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca991bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Cora node-classification dataset using PyG's Planetoid wrapper\n",
    "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")\n",
    "# Inspect the first graph/data object\n",
    "cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: train or load a node-level classifier (MLP or GNN).\n",
    "# Inputs: model_name (used for checkpoint naming), dataset (PyG dataset), and model kwargs\n",
    "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
    "    # Reproducibility for training runs\n",
    "    pl.seed_everything(42)\n",
    "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with a ModelCheckpoint callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=root_dir,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")\n",
    "        ],\n",
    "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "        devices=1,\n",
    "        max_epochs=200,\n",
    "        enable_progress_bar=False,\n",
    "    )  # False because epoch size is 1\n",
    "    trainer.logger._default_hp_metric = (\n",
    "        None  # Optional logging argument that we don't need\n",
    "    )\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = NodeLevelGNN(\n",
    "            model_name=model_name,\n",
    "            c_in=dataset.num_node_features,\n",
    "            c_out=dataset.num_classes,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        trainer.fit(model, node_data_loader, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )\n",
    "\n",
    "    # Evaluate the best model: compute train/val/test accuracies\n",
    "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    _, train_acc = model.forward(batch, mode=\"train\")\n",
    "    _, val_acc = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_acc, \"val\": val_acc, \"test\": test_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8917d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to pretty-print train/val/test accuracies from result dict\n",
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(f\"Train accuracy: {(100.0 * result_dict['train']):4.2f}%\")\n",
    "    if \"val\" in result_dict:\n",
    "        print(f\"Val accuracy:   {(100.0 * result_dict['val']):4.2f}%\")\n",
    "    print(f\"Test accuracy:  {(100.0 * result_dict['test']):4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.5.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelMLP.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 97.86%\n",
      "Val accuracy:   52.80%\n",
      "Test accuracy:  60.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "# Train (or load) a simple MLP node classifier and print results\n",
    "node_mlp_model, node_mlp_result = train_node_classifier(\n",
    "    model_name=\"MLP\", dataset=cora_dataset, c_hidden=16, num_layers=2, dp_rate=0.1\n",
    ")\n",
    "\n",
    "print_results(node_mlp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd314578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.5.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelGNN.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n",
      "Train accuracy: 100.00%\n",
      "Val accuracy:   77.80%\n",
      "Test accuracy:  82.40%\n"
     ]
    }
   ],
   "source": [
    "# Train (or load) a GNN node classifier (using GCN layers) and print results\n",
    "node_gnn_model, node_gnn_result = train_node_classifier(\n",
    "    model_name=\"GNN\",\n",
    "    layer_name=\"GCN\",\n",
    "    dataset=cora_dataset,\n",
    "    c_hidden=16,\n",
    "    num_layers=2,\n",
    "    dp_rate=0.1,\n",
    ")\n",
    "print_results(node_gnn_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3486d2",
   "metadata": {},
   "source": [
    "## Graph-Level Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MUTAG graph classification dataset (TUDataset format)\n",
    "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bd28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
      "Length: 188\n",
      "Average label: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity checks on the TUDataset object\n",
    "print(\"Data object:\", tu_dataset.data)\n",
    "print(\"Length:\", len(tu_dataset))\n",
    "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ef6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the MUTAG dataset into train and test subsets\n",
    "torch.manual_seed(13)\n",
    "tu_dataset.shuffle()\n",
    "train_dataset = tu_dataset[:150]\n",
    "test_dataset = tu_dataset[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batched graph classification training and evaluation\n",
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(\n",
    "    test_dataset, batch_size=64\n",
    ")  # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e41283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
      "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Peek at a batch from the test loader to understand its structure\n",
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Labels:\", batch.y[:10])\n",
    "print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: train or load a graph-level classifier. Uses GraphLevelGNN class from utils.py\n",
    "def train_graph_classifier(model_name, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with a ModelCheckpoint callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=root_dir,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")\n",
    "        ],\n",
    "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "        devices=1,\n",
    "        max_epochs=500,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer.logger._default_hp_metric = (\n",
    "        None  # Optional logging argument that we don't need\n",
    "    )\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(\n",
    "            c_in=tu_dataset.num_node_features,\n",
    "            c_out=1 if tu_dataset.num_classes == 2 else tu_dataset.num_classes,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        model = GraphLevelGNN.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"train\": train_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dbbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.5.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/GraphLevelGraphConv.ckpt`\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:484: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/nitingupta/usc/fa25/csce584/neural-network-applications/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "# Train (or load) a graph-level classifier using GraphConv layers\n",
    "model, result = train_graph_classifier(\n",
    "    model_name=\"GraphConv\",\n",
    "    c_hidden=256,\n",
    "    layer_name=\"GraphConv\",\n",
    "    num_layers=3,\n",
    "    dp_rate_linear=0.5,\n",
    "    dp_rate=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38de1aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 93.28%\n",
      "Test performance:  92.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train performance: {100.0 * result['train']:4.2f}%\")\n",
    "print(f\"Test performance:  {100.0 * result['test']:4.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-applications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
